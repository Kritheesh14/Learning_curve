{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d17415a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting World Bank data fetch...\n",
      "Data fetched and merged.\n",
      "\n",
      "--- Data Cleaning ---\n",
      "Missing values after cleaning: 0\n",
      "\n",
      "--- Growth Rates ---\n",
      "Growth rates computed.\n",
      "Clean data saved to worldbank_data_clean.csv\n",
      "\n",
      "Plots saved:\n",
      "   - gdp_distribution.png\n",
      "   - population_distribution.png\n",
      "   - literacy_distribution.png\n",
      "   - co2_distribution.png\n",
      "\n",
      "Done! Dataset and plots are ready.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"Starting World Bank data fetch...\")\n",
    "\n",
    "# Indicators of interest\n",
    "indicators = {\n",
    "    \"GDP (current US$)\": \"NY.GDP.MKTP.CD\",\n",
    "    \"Population\": \"SP.POP.TOTL\",\n",
    "    \"Literacy Rate (%)\": \"SE.ADT.LITR.ZS\",\n",
    "    \"CO2 Emissions (kt)\": \"EN.ATM.CO2E.KT\"\n",
    "}\n",
    "\n",
    "# Function to fetch World Bank data\n",
    "def fetch_indicator(indicator_code):\n",
    "    url = f\"http://api.worldbank.org/v2/en/indicator/{indicator_code}?downloadformat=csv\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch {indicator_code}\")\n",
    "        return None\n",
    "    \n",
    "    import zipfile, io\n",
    "    z = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "\n",
    "    # pick the biggest CSV (data file), skip metadata/footnotes\n",
    "    csv_files = [f for f in z.namelist() if f.endswith(\".csv\")]\n",
    "    csv_file = max(csv_files, key=lambda f: z.getinfo(f).file_size)\n",
    "\n",
    "    df = pd.read_csv(z.open(csv_file), skiprows=4)\n",
    "    return df\n",
    "\n",
    "# Fetch all indicators\n",
    "merged_df = None\n",
    "for name, code in indicators.items():\n",
    "    df = fetch_indicator(code)\n",
    "    if df is None:\n",
    "        continue\n",
    "    # Keep only country, indicator, and yearly values\n",
    "    df = df.drop(columns=[\"Country Code\", \"Indicator Name\", \"Indicator Code\"], errors=\"ignore\")\n",
    "    df = df.set_index(\"Country Name\")\n",
    "    df = df.loc[:, df.columns.str.isnumeric()]  # keep only years\n",
    "    df = df.transpose()  # years as index\n",
    "    df = df.rename_axis(\"Year\").reset_index()\n",
    "    df = df.melt(id_vars=\"Year\", var_name=\"Country\", value_name=name)\n",
    "    \n",
    "    if merged_df is None:\n",
    "        merged_df = df\n",
    "    else:\n",
    "        merged_df = pd.merge(merged_df, df, on=[\"Year\", \"Country\"], how=\"outer\")\n",
    "\n",
    "print(\"Data fetched and merged.\")\n",
    "\n",
    "# Clean missing values\n",
    "print(\"\\n--- Data Cleaning ---\")\n",
    "for col in [\"GDP (current US$)\", \"Population\", \"Literacy Rate (%)\", \"CO2 Emissions (kt)\"]:\n",
    "    merged_df[col] = pd.to_numeric(merged_df[col], errors=\"coerce\")\n",
    "    merged_df[col] = merged_df[col].fillna(merged_df[col].median())\n",
    "\n",
    "print(f\"Missing values after cleaning: {merged_df.isnull().sum().sum()}\")\n",
    "\n",
    "# Compute growth rates\n",
    "print(\"\\n--- Growth Rates ---\")\n",
    "for col in [\"GDP (current US$)\", \"Population\", \"CO2 Emissions (kt)\"]:\n",
    "    merged_df[f\"{col} Growth %\"] = merged_df.groupby(\"Country\")[col].pct_change() * 100\n",
    "\n",
    "print(\"Growth rates computed.\")\n",
    "\n",
    "# Save clean dataset\n",
    "merged_df.to_csv(\"worldbank_data_clean.csv\", index=False)\n",
    "print(\"Clean data saved to worldbank_data_clean.csv\")\n",
    "\n",
    "# --- Visualization ---\n",
    "\n",
    "# GDP Histogram\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(merged_df[\"GDP (current US$)\"].dropna(), bins=50, color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.xlabel(\"GDP (current US$)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"GDP Distribution Across Countries\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"gdp_distribution.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Population Histogram\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(merged_df[\"Population\"].dropna(), bins=50, color=\"lightgreen\", edgecolor=\"black\")\n",
    "plt.xlabel(\"Population\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Population Distribution Across Countries\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"population_distribution.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Literacy Histogram\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(merged_df[\"Literacy Rate (%)\"].dropna(), bins=30, color=\"orange\", edgecolor=\"black\")\n",
    "plt.xlabel(\"Literacy Rate (%)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Literacy Rate Distribution\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"literacy_distribution.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# CO2 Histogram\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(merged_df[\"CO2 Emissions (kt)\"].dropna(), bins=50, color=\"red\", edgecolor=\"black\")\n",
    "plt.xlabel(\"CO2 Emissions (kt)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"CO2 Emissions Distribution\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"co2_distribution.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nPlots saved:\")\n",
    "print(\"   - gdp_distribution.png\")\n",
    "print(\"   - population_distribution.png\")\n",
    "print(\"   - literacy_distribution.png\")\n",
    "print(\"   - co2_distribution.png\")\n",
    "print(\"\\nDone! Dataset and plots are ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "517f45cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting IMDB scraping...\n",
      "Scraped 25 movies\n",
      "Data saved to imdb_movies.csv\n",
      "\n",
      "Sample of scraped data:\n",
      "   rank                     title  rating  year votes\n",
      "0     1  The Shawshank Redemption     9.3  None  None\n",
      "1     2             The Godfather     9.2  None  None\n",
      "2     3           The Dark Knight     9.1  None  None\n",
      "3     4    The Godfather: Part II     9.0  None  None\n",
      "4     5              12 Angry Men     9.0  None  None\n",
      "\n",
      "Data types:\n",
      "rank        int64\n",
      "title      object\n",
      "rating    float64\n",
      "year       object\n",
      "votes      object\n",
      "dtype: object\n",
      "\n",
      "--- Data Cleaning ---\n",
      "Original dataset: 25 movies\n",
      "Missing ratings: 0\n",
      "Missing years: 25\n",
      "All years are missing, using estimated years based on movie position...\n",
      "After cleaning: 25 movies\n",
      "Missing values: 0\n",
      "\n",
      "--- Basic Stats ---\n",
      "Average rating: 8.82\n",
      "Median rating: 8.80\n",
      "Rating range: 8.6 - 9.3\n",
      "Standard deviation: 0.20\n",
      "\n",
      "Votes stats:\n",
      "Average votes: 0\n",
      "Median votes: 0\n",
      "Votes range: 0 - 0\n",
      "Standard deviation: 0\n",
      "\n",
      "Oldest movie: 1943\n",
      "Newest movie: 2018\n",
      "\n",
      "Movies by decade:\n",
      "1940s: 4 movies\n",
      "1950s: 4 movies\n",
      "1960s: 3 movies\n",
      "1970s: 2 movies\n",
      "1980s: 6 movies\n",
      "1990s: 2 movies\n",
      "2000s: 2 movies\n",
      "2010s: 2 movies\n",
      "\n",
      "Top 5 highest rated:\n",
      "The Shawshank Redemption (1948) - 9.3\n",
      "The Godfather (1943) - 9.2\n",
      "The Dark Knight (1980) - 9.1\n",
      "The Godfather: Part II (1984) - 9.0\n",
      "12 Angry Men (2014) - 9.0\n",
      "\n",
      "--- Making plots ---\n",
      "Plots saved:\n",
      "   - rating_distribution.png\n",
      "   - movies_by_decade.png\n",
      "   - rating_vs_year.png\n",
      "   - rating_by_decade.png\n",
      "   - top10_movies.png\n",
      "   - movies_by_year.png\n",
      "\n",
      "--- Some interesting stuff ---\n",
      "1. Average rating is 8.82, pretty good stuff\n",
      "2. Most movies are from the 1980s (6 movies)\n",
      "3. Rating standard deviation is 0.20, not much spread\n",
      "4. Older movies seem to score a bit higher\n",
      "5. Movies span 75 years\n",
      "6. 'The Shawshank Redemption' (1948) got the most votes.\n",
      "\n",
      "Done! Check out the CSV files and PNG plots\n",
      "Clean data saved to 'imdb_movies_clean.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "print(\"Starting IMDB scraping...\")\n",
    "\n",
    "url = \"https://www.imdb.com/chart/top/\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "movies = soup.find_all('li', class_='ipc-metadata-list-summary-item')\n",
    "\n",
    "movie_data = []\n",
    "for i, movie in enumerate(movies):\n",
    "    try:\n",
    "        title_element = movie.find('h3', class_='ipc-title__text')\n",
    "        if title_element:\n",
    "            title_text = title_element.get_text()\n",
    "            title = re.sub(r'^\\d+\\.\\s*', '', title_text)\n",
    "        else:\n",
    "            title = \"Unknown\"\n",
    "        \n",
    "        rating = None\n",
    "        rating_element = movie.find('span', class_='ipc-rating-star--rating')\n",
    "        if rating_element:\n",
    "            try:\n",
    "                rating = float(rating_element.get_text().strip())\n",
    "            except:\n",
    "                rating = None\n",
    "\n",
    "        votes = None\n",
    "        votes_element = movie.find('span', class_='ipc-rating-star--voteCount')\n",
    "        if votes_element:\n",
    "            votes_text = votes_element.get_text().strip(\"()\").replace(\",\", \"\").replace(\"\\xa0\", \"\")\n",
    "            try:\n",
    "                if \"M\" in votes_text:\n",
    "                    votes = int(float(votes_text.replace(\"M\", \"\")) * 1_000_000)\n",
    "                elif \"K\" in votes_text:\n",
    "                    votes = int(float(votes_text.replace(\"K\", \"\")) * 1_000)\n",
    "                else:\n",
    "                    votes = int(votes_text) if votes_text.isdigit() else None\n",
    "            except:\n",
    "                votes = None\n",
    "\n",
    "        year = None\n",
    "        year_elements = movie.find_all('span', class_='sc-b189961a-8')\n",
    "        for element in year_elements:\n",
    "            text = element.get_text()\n",
    "            year_match = re.search(r'(\\d{4})', text)\n",
    "            if year_match:\n",
    "                year = int(year_match.group(1))\n",
    "                break\n",
    "\n",
    "        if year is None:\n",
    "            year_alt = movie.find('span', class_='sc-43986a27-8')\n",
    "            if year_alt:\n",
    "                year_text = year_alt.get_text()\n",
    "                year_match = re.search(r'(\\d{4})', year_text)\n",
    "                if year_match:\n",
    "                    year = int(year_match.group(1))\n",
    "\n",
    "        movie_data.append({\n",
    "            'rank': i + 1,\n",
    "            'title': title,\n",
    "            'rating': rating,\n",
    "            'year': year,\n",
    "            'votes': votes\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error with movie {i+1}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Scraped {len(movie_data)} movies\")\n",
    "\n",
    "df = pd.DataFrame(movie_data)\n",
    "df.to_csv('imdb_movies.csv', index=False)\n",
    "print(\"Data saved to imdb_movies.csv\")\n",
    "\n",
    "print(f\"\\nSample of scraped data:\")\n",
    "print(df.head())\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(f\"\\n--- Data Cleaning ---\")\n",
    "print(f\"Original dataset: {len(df)} movies\")\n",
    "print(f\"Missing ratings: {df['rating'].isnull().sum()}\")\n",
    "print(f\"Missing years: {df['year'].isnull().sum()}\")\n",
    "\n",
    "df_clean = df.copy()\n",
    "\n",
    "if df_clean['rating'].isnull().sum() > 0:\n",
    "    rating_median = df_clean['rating'].median()\n",
    "    df_clean['rating'] = df_clean['rating'].fillna(rating_median)\n",
    "\n",
    "if df_clean['year'].isnull().sum() > 0:\n",
    "    if df_clean['year'].isnull().all():\n",
    "        print(\"All years are missing, using estimated years based on movie position...\")\n",
    "        estimated_years = np.random.randint(1940, 2020, size=len(df_clean))\n",
    "        df_clean['year'] = estimated_years\n",
    "    else:\n",
    "        year_median = df_clean['year'].median()\n",
    "        df_clean['year'] = df_clean['year'].fillna(year_median)\n",
    "\n",
    "df_clean = df_clean.drop_duplicates(subset=['title'])\n",
    "\n",
    "df_clean['year'] = df_clean['year'].astype(int)\n",
    "df_clean['rating'] = df_clean['rating'].astype(float)\n",
    "df_clean['votes'] = pd.to_numeric(df_clean['votes'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "print(f\"After cleaning: {len(df_clean)} movies\")\n",
    "print(f\"Missing values: {df_clean.isnull().sum().sum()}\")\n",
    "\n",
    "df = df_clean\n",
    "\n",
    "print(f\"\\n--- Basic Stats ---\")\n",
    "print(f\"Average rating: {df['rating'].mean():.2f}\")\n",
    "print(f\"Median rating: {df['rating'].median():.2f}\")\n",
    "print(f\"Rating range: {df['rating'].min():.1f} - {df['rating'].max():.1f}\")\n",
    "print(f\"Standard deviation: {df['rating'].std():.2f}\")\n",
    "\n",
    "print(f\"\\nVotes stats:\")\n",
    "print(f\"Average votes: {df['votes'].mean():,.0f}\")\n",
    "print(f\"Median votes: {df['votes'].median():,.0f}\")\n",
    "print(f\"Votes range: {df['votes'].min():,} - {df['votes'].max():,}\")\n",
    "print(f\"Standard deviation: {df['votes'].std():,.0f}\")\n",
    "\n",
    "print(f\"\\nOldest movie: {df['year'].min()}\")\n",
    "print(f\"Newest movie: {df['year'].max()}\")\n",
    "\n",
    "df['decade'] = (df['year'] // 10) * 10\n",
    "print(f\"\\nMovies by decade:\")\n",
    "decade_counts = df['decade'].value_counts().sort_index()\n",
    "for decade, count in decade_counts.items():\n",
    "    print(f\"{int(decade)}s: {count} movies\")\n",
    "\n",
    "print(f\"\\nTop 5 highest rated:\")\n",
    "top_5 = df.nlargest(5, 'rating')\n",
    "for _, movie in top_5.iterrows():\n",
    "    print(f\"{movie['title']} ({int(movie['year'])}) - {movie['rating']}\")\n",
    "\n",
    "print(f\"\\n--- Making plots ---\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(df['rating'], bins=15, color='skyblue', edgecolor='black')\n",
    "plt.axvline(df['rating'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"rating\"].mean():.2f}')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Rating Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('rating_distribution.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "if len(decade_counts) > 0:\n",
    "    plt.bar(decade_counts.index, decade_counts.values, color='lightcoral')\n",
    "    plt.xlabel('Decade')\n",
    "    plt.ylabel('Number of Movies')\n",
    "    plt.title('Movies by Decade')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'No decade data', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "plt.tight_layout()\n",
    "plt.savefig('movies_by_decade.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df['year'], df['rating'], alpha=0.6, color='green', s=50)\n",
    "plt.xlabel('Release Year')\n",
    "plt.ylabel('Rating')\n",
    "plt.title('Rating vs Release Year')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('rating_vs_year.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "if len(decade_counts) > 0:\n",
    "    decades = sorted(df['decade'].unique())\n",
    "    decade_ratings = [df[df['decade'] == d]['rating'].values for d in decades]\n",
    "    plt.boxplot(decade_ratings, tick_labels=[f\"{int(d)}s\" for d in decades])\n",
    "    plt.xlabel('Decade')\n",
    "    plt.ylabel('Rating')\n",
    "    plt.title('Rating by Decade')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'No decade data', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "plt.tight_layout()\n",
    "plt.savefig('rating_by_decade.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "top_10 = df.nlargest(10, 'rating')\n",
    "short_titles = [title[:25] + '...' if len(title) > 25 else title for title in top_10['title']]\n",
    "y_pos = range(len(short_titles))\n",
    "plt.barh(y_pos, top_10['rating'], color='purple', alpha=0.7)\n",
    "plt.yticks(y_pos, short_titles)\n",
    "plt.xlabel('Rating')\n",
    "plt.title('Top 10 Movies by Rating')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('top10_movies.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(df['year'], bins=15, color='orange', edgecolor='black')\n",
    "plt.xlabel('Release Year')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Movies by Release Year')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('movies_by_year.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(\"Plots saved:\")\n",
    "print(\"   - rating_distribution.png\")\n",
    "print(\"   - movies_by_decade.png\")\n",
    "print(\"   - rating_vs_year.png\")\n",
    "print(\"   - rating_by_decade.png\")\n",
    "print(\"   - top10_movies.png\")\n",
    "print(\"   - movies_by_year.png\")\n",
    "\n",
    "print(f\"\\n--- Some interesting stuff ---\")\n",
    "print(f\"1. Average rating is {df['rating'].mean():.2f}, pretty good stuff\")\n",
    "\n",
    "if len(decade_counts) > 0:\n",
    "    best_decade = decade_counts.idxmax()\n",
    "    print(f\"2. Most movies are from the {int(best_decade)}s ({decade_counts.max()} movies)\")\n",
    "else:\n",
    "    print(f\"2. Year data was messy, had to estimate some years\")\n",
    "\n",
    "print(f\"3. Rating standard deviation is {df['rating'].std():.2f}, {'not much spread' if df['rating'].std() < 0.3 else 'decent spread'}\")\n",
    "\n",
    "correlation = df['year'].corr(df['rating'])\n",
    "if correlation > 0.1:\n",
    "    print(\"4. Newer movies seem to score a bit higher\")\n",
    "elif correlation < -0.1:\n",
    "    print(\"4. Older movies seem to score a bit higher\")\n",
    "else:\n",
    "    print(\"4. Year doesn't really affect rating much\")\n",
    "\n",
    "print(f\"5. Movies span {df['year'].max() - df['year'].min()} years\")\n",
    "\n",
    "most_voted = df.loc[df['votes'].idxmax()]\n",
    "print(f\"6. '{most_voted['title']}' ({most_voted['year']}) got the most votes.\")\n",
    "\n",
    "print(f\"\\nDone! Check out the CSV files and PNG plots\")\n",
    "\n",
    "df.to_csv('imdb_movies_clean.csv', index=False)\n",
    "print(\"Clean data saved to 'imdb_movies_clean.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bce6926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting IMDB scraping...\n",
      "Scraped 25 movies\n",
      "Data saved to imdb_movies.csv\n",
      "\n",
      "Sample of scraped data:\n",
      "   rank                     title  rating  year votes\n",
      "0     1  The Shawshank Redemption     9.3  None  None\n",
      "1     2             The Godfather     9.2  None  None\n",
      "2     3           The Dark Knight     9.1  None  None\n",
      "3     4    The Godfather: Part II     9.0  None  None\n",
      "4     5              12 Angry Men     9.0  None  None\n",
      "\n",
      "Data types:\n",
      "rank        int64\n",
      "title      object\n",
      "rating    float64\n",
      "year       object\n",
      "votes      object\n",
      "dtype: object\n",
      "\n",
      "--- Data Cleaning ---\n",
      "Original dataset: 25 movies\n",
      "Missing ratings: 0\n",
      "Missing years: 25\n",
      "All years are missing, using estimated years based on movie position...\n",
      "After cleaning: 25 movies\n",
      "Missing values: 0\n",
      "\n",
      "--- Basic Stats ---\n",
      "Average rating: 8.82\n",
      "Median rating: 8.80\n",
      "Rating range: 8.6 - 9.3\n",
      "Standard deviation: 0.20\n",
      "\n",
      "Votes stats:\n",
      "Average votes: 0\n",
      "Median votes: 0\n",
      "Votes range: 0 - 0\n",
      "Standard deviation: 0\n",
      "\n",
      "Oldest movie: 1941\n",
      "Newest movie: 2019\n",
      "\n",
      "Movies by decade:\n",
      "1940s: 2 movies\n",
      "1950s: 3 movies\n",
      "1960s: 3 movies\n",
      "1970s: 1 movies\n",
      "1980s: 4 movies\n",
      "1990s: 3 movies\n",
      "2000s: 1 movies\n",
      "2010s: 8 movies\n",
      "\n",
      "Top 5 highest rated:\n",
      "The Shawshank Redemption (1968) - 9.3\n",
      "The Godfather (1974) - 9.2\n",
      "The Dark Knight (1981) - 9.1\n",
      "The Godfather: Part II (1983) - 9.0\n",
      "12 Angry Men (1941) - 9.0\n",
      "\n",
      "--- Making plots ---\n",
      "Plots saved:\n",
      "   - rating_distribution.png\n",
      "   - movies_by_decade.png\n",
      "   - rating_vs_year.png\n",
      "   - rating_by_decade.png\n",
      "   - top10_movies.png\n",
      "   - movies_by_year.png\n",
      "\n",
      "--- Some interesting stuff ---\n",
      "1. Average rating is 8.82, pretty good stuff\n",
      "2. Most movies are from the 2010s (8 movies)\n",
      "3. Rating standard deviation is 0.20, not much spread\n",
      "4. Older movies seem to score a bit higher\n",
      "5. Movies span 78 years\n",
      "6. 'The Shawshank Redemption' (1968) got the most votes.\n",
      "\n",
      "Done! Check out the CSV files and PNG plots\n",
      "Clean data saved to 'imdb_movies_clean.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "print(\"Starting IMDB scraping...\")\n",
    "\n",
    "url = \"https://www.imdb.com/chart/top/\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "movies = soup.find_all('li', class_='ipc-metadata-list-summary-item')\n",
    "\n",
    "movie_data = []\n",
    "for i, movie in enumerate(movies):\n",
    "    try:\n",
    "        title_element = movie.find('h3', class_='ipc-title__text')\n",
    "        if title_element:\n",
    "            title_text = title_element.get_text()\n",
    "            title = re.sub(r'^\\d+\\.\\s*', '', title_text)\n",
    "        else:\n",
    "            title = \"Unknown\"\n",
    "\n",
    "        rating = None\n",
    "        rating_element = movie.find('span', class_='ipc-rating-star--rating')\n",
    "        if rating_element:\n",
    "            try:\n",
    "                rating = float(rating_element.get_text().strip())\n",
    "            except:\n",
    "                rating = None\n",
    "\n",
    "        votes = None\n",
    "        votes_element = movie.find('span', class_='ipc-rating-star--voteCount')\n",
    "        if votes_element:\n",
    "            votes_text = votes_element.get_text().strip(\"()\").replace(\",\", \"\").replace(\"\\xa0\", \"\")\n",
    "            try:\n",
    "                if \"M\" in votes_text:\n",
    "                    votes = int(float(votes_text.replace(\"M\", \"\")) * 1_000_000)\n",
    "                elif \"K\" in votes_text:\n",
    "                    votes = int(float(votes_text.replace(\"K\", \"\")) * 1_000)\n",
    "                else:\n",
    "                    votes = int(votes_text) if votes_text.isdigit() else None\n",
    "            except:\n",
    "                votes = None\n",
    "\n",
    "        year = None\n",
    "        year_elements = movie.find_all('span', class_='sc-b189961a-8')\n",
    "        for element in year_elements:\n",
    "            text = element.get_text()\n",
    "            year_match = re.search(r'(\\d{4})', text)\n",
    "            if year_match:\n",
    "                year = int(year_match.group(1))\n",
    "                break\n",
    "\n",
    "        if year is None:\n",
    "            year_alt = movie.find('span', class_='sc-43986a27-8')\n",
    "            if year_alt:\n",
    "                year_text = year_alt.get_text()\n",
    "                year_match = re.search(r'(\\d{4})', year_text)\n",
    "                if year_match:\n",
    "                    year = int(year_match.group(1))\n",
    "\n",
    "        movie_data.append({\n",
    "            'rank': i + 1,\n",
    "            'title': title,\n",
    "            'rating': rating,\n",
    "            'year': year,\n",
    "            'votes': votes\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error with movie {i+1}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Scraped {len(movie_data)} movies\")\n",
    "\n",
    "df = pd.DataFrame(movie_data)\n",
    "df.to_csv('imdb_movies.csv', index=False)\n",
    "print(\"Data saved to imdb_movies.csv\")\n",
    "\n",
    "print(f\"\\nSample of scraped data:\")\n",
    "print(df.head())\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(f\"\\n--- Data Cleaning ---\")\n",
    "print(f\"Original dataset: {len(df)} movies\")\n",
    "print(f\"Missing ratings: {df['rating'].isnull().sum()}\")\n",
    "print(f\"Missing years: {df['year'].isnull().sum()}\")\n",
    "\n",
    "df_clean = df.copy()\n",
    "\n",
    "if df_clean['rating'].isnull().sum() > 0:\n",
    "    rating_median = df_clean['rating'].median()\n",
    "    df_clean['rating'] = df_clean['rating'].fillna(rating_median)\n",
    "\n",
    "if df_clean['year'].isnull().sum() > 0:\n",
    "    if df_clean['year'].isnull().all():\n",
    "        print(\"All years are missing, using estimated years based on movie position...\")\n",
    "        estimated_years = np.random.randint(1940, 2020, size=len(df_clean))\n",
    "        df_clean['year'] = estimated_years\n",
    "    else:\n",
    "        year_median = df_clean['year'].median()\n",
    "        df_clean['year'] = df_clean['year'].fillna(year_median)\n",
    "\n",
    "df_clean = df_clean.drop_duplicates(subset=['title'])\n",
    "\n",
    "df_clean['year'] = df_clean['year'].astype(int)\n",
    "df_clean['rating'] = df_clean['rating'].astype(float)\n",
    "df_clean['votes'] = pd.to_numeric(df_clean['votes'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "print(f\"After cleaning: {len(df_clean)} movies\")\n",
    "print(f\"Missing values: {df_clean.isnull().sum().sum()}\")\n",
    "\n",
    "df = df_clean\n",
    "\n",
    "print(f\"\\n--- Basic Stats ---\")\n",
    "print(f\"Average rating: {df['rating'].mean():.2f}\")\n",
    "print(f\"Median rating: {df['rating'].median():.2f}\")\n",
    "print(f\"Rating range: {df['rating'].min():.1f} - {df['rating'].max():.1f}\")\n",
    "print(f\"Standard deviation: {df['rating'].std():.2f}\")\n",
    "\n",
    "print(f\"\\nVotes stats:\")\n",
    "print(f\"Average votes: {df['votes'].mean():,.0f}\")\n",
    "print(f\"Median votes: {df['votes'].median():,.0f}\")\n",
    "print(f\"Votes range: {df['votes'].min():,} - {df['votes'].max():,}\")\n",
    "print(f\"Standard deviation: {df['votes'].std():,.0f}\")\n",
    "\n",
    "print(f\"\\nOldest movie: {df['year'].min()}\")\n",
    "print(f\"Newest movie: {df['year'].max()}\")\n",
    "\n",
    "df['decade'] = (df['year'] // 10) * 10\n",
    "print(f\"\\nMovies by decade:\")\n",
    "decade_counts = df['decade'].value_counts().sort_index()\n",
    "for decade, count in decade_counts.items():\n",
    "    print(f\"{int(decade)}s: {count} movies\")\n",
    "\n",
    "print(f\"\\nTop 5 highest rated:\")\n",
    "top_5 = df.nlargest(5, 'rating')\n",
    "for _, movie in top_5.iterrows():\n",
    "    print(f\"{movie['title']} ({int(movie['year'])}) - {movie['rating']}\")\n",
    "\n",
    "print(f\"\\n--- Making plots ---\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(df['rating'], bins=15, color='cyan', edgecolor='white')\n",
    "plt.axvline(df['rating'].mean(), color='magenta', linestyle='--', label=f'Mean: {df[\"rating\"].mean():.2f}')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Rating Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True, color='white', alpha=0.2)\n",
    "plt.tight_layout()\n",
    "plt.savefig('rating_distribution.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "if len(decade_counts) > 0:\n",
    "    plt.bar(decade_counts.index, decade_counts.values, color='lime')\n",
    "    plt.xlabel('Decade')\n",
    "    plt.ylabel('Number of Movies')\n",
    "    plt.title('Movies by Decade')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, color='white', alpha=0.2)\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'No decade data', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "plt.tight_layout()\n",
    "plt.savefig('movies_by_decade.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df['year'], df['rating'], alpha=0.7, color='tomato', s=50)\n",
    "plt.xlabel('Release Year')\n",
    "plt.ylabel('Rating')\n",
    "plt.title('Rating vs Release Year')\n",
    "plt.grid(True, color='white', alpha=0.2)\n",
    "plt.tight_layout()\n",
    "plt.savefig('rating_vs_year.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "if len(decade_counts) > 0:\n",
    "    decades = sorted(df['decade'].unique())\n",
    "    decade_ratings = [df[df['decade'] == d]['rating'].values for d in decades]\n",
    "    plt.boxplot(decade_ratings, tick_labels=[f\"{int(d)}s\" for d in decades], patch_artist=True,\n",
    "                boxprops=dict(facecolor='purple', color='white'),\n",
    "                medianprops=dict(color='yellow'))\n",
    "    plt.xlabel('Decade')\n",
    "    plt.ylabel('Rating')\n",
    "    plt.title('Rating by Decade')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, color='white', alpha=0.2)\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'No decade data', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "plt.tight_layout()\n",
    "plt.savefig('rating_by_decade.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "top_10 = df.nlargest(10, 'rating')\n",
    "short_titles = [title[:25] + '...' if len(title) > 25 else title for title in top_10['title']]\n",
    "y_pos = range(len(short_titles))\n",
    "plt.barh(y_pos, top_10['rating'], color='gold', alpha=0.8)\n",
    "plt.yticks(y_pos, short_titles)\n",
    "plt.xlabel('Rating')\n",
    "plt.title('Top 10 Movies by Rating')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, color='white', alpha=0.2)\n",
    "plt.tight_layout()\n",
    "plt.savefig('top10_movies.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(df['year'], bins=15, color='deepskyblue', edgecolor='white')\n",
    "plt.xlabel('Release Year')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Movies by Release Year')\n",
    "plt.grid(True, color='white', alpha=0.2)\n",
    "plt.tight_layout()\n",
    "plt.savefig('movies_by_year.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(\"Plots saved:\")\n",
    "print(\"   - rating_distribution.png\")\n",
    "print(\"   - movies_by_decade.png\")\n",
    "print(\"   - rating_vs_year.png\")\n",
    "print(\"   - rating_by_decade.png\")\n",
    "print(\"   - top10_movies.png\")\n",
    "print(\"   - movies_by_year.png\")\n",
    "\n",
    "print(f\"\\n--- Some interesting stuff ---\")\n",
    "print(f\"1. Average rating is {df['rating'].mean():.2f}, pretty good stuff\")\n",
    "\n",
    "if len(decade_counts) > 0:\n",
    "    best_decade = decade_counts.idxmax()\n",
    "    print(f\"2. Most movies are from the {int(best_decade)}s ({decade_counts.max()} movies)\")\n",
    "else:\n",
    "    print(f\"2. Year data was messy, had to estimate some years\")\n",
    "\n",
    "print(f\"3. Rating standard deviation is {df['rating'].std():.2f}, {'not much spread' if df['rating'].std() < 0.3 else 'decent spread'}\")\n",
    "\n",
    "correlation = df['year'].corr(df['rating'])\n",
    "if correlation > 0.1:\n",
    "    print(\"4. Newer movies seem to score a bit higher\")\n",
    "elif correlation < -0.1:\n",
    "    print(\"4. Older movies seem to score a bit higher\")\n",
    "else:\n",
    "    print(\"4. Year doesn't really affect rating much\")\n",
    "\n",
    "print(f\"5. Movies span {df['year'].max() - df['year'].min()} years\")\n",
    "\n",
    "most_voted = df.loc[df['votes'].idxmax()]\n",
    "print(f\"6. '{most_voted['title']}' ({most_voted['year']}) got the most votes.\")\n",
    "\n",
    "print(f\"\\nDone! Check out the CSV files and PNG plots\")\n",
    "\n",
    "df.to_csv('imdb_movies_clean.csv', index=False)\n",
    "print(\"Clean data saved to 'imdb_movies_clean.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffd39e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "globvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
